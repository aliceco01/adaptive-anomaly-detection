{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Explainability with SHAP\n",
    "\n",
    "To improve transparency and root cause analysis, we use SHAP (SHapley Additive exPlanations) to explain anomaly predictions from the trained model.\n",
    "\n",
    "This helps identify which features contributed most to a given anomaly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import shap\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from src.generate_data import generate_synthetic_telemetry\n",
    "from src.preprocess import normalize_data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load and process data\n",
    "df = generate_synthetic_telemetry()\n",
    "\n",
    "# Reuse features from previous notebooks\n",
    "df['cpu_rolling_mean'] = df['cpu'].rolling(window=20).mean()\n",
    "df['cpu_rolling_std'] = df['cpu'].rolling(window=20).std()\n",
    "df['latency_diff'] = df['latency'].diff()\n",
    "df['errors_rolling_sum'] = df['errors'].rolling(window=10).sum()\n",
    "df['latency_fft_mean'] = pd.Series(\n",
    "    [np.mean(np.abs(np.fft.fft(df['latency'][i:i+64]))) if i+64 < len(df) else np.nan for i in range(len(df))]\n",
    ")\n",
    "df['cpu_z'] = (df['cpu'] - df['cpu'].mean()) / df['cpu'].std()\n",
    "df['latency_z'] = (df['latency'] - df['latency'].mean()) / df['latency'].std()\n",
    "df['cpu_lag1'] = df['cpu'].shift(1)\n",
    "df['latency_lag3'] = df['latency'].shift(3)\n",
    "df['errors_lag2'] = df['errors'].shift(2)\n",
    "df['latency_cpu_corr_20'] = df['latency'].rolling(window=20).corr(df['cpu'])\n",
    "\n",
    "df_clean = df.dropna()\n",
    "X = normalize_data(df_clean)\n",
    "\n",
    "# Train model\n",
    "model = IsolationForest(contamination=0.05, random_state=42)\n",
    "model.fit(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the SHAP Kernel Explainer since Isolation Forest is not directly supported by TreeExplainer.\n",
    "This may be slow for large datasets, so we limit to a small subset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Use SHAP KernelExplainer (model must have decision_function)\n",
    "explainer = shap.KernelExplainer(model.decision_function, shap.kmeans(X, 10))\n",
    "\n",
    "# Pick a sample anomaly (e.g. index 310, known injected anomaly)\n",
    "i = 310\n",
    "shap_values = explainer.shap_values(X.iloc[[i]])\n",
    "\n",
    "# Visualize explanation\n",
    "shap.initjs()\n",
    "shap.force_plot(explainer.expected_value, shap_values, X.iloc[i], matplotlib=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alternatively: explain multiple predictions\n",
    "subset = X.sample(50, random_state=42)\n",
    "shap_vals = explainer.shap_values(subset)\n",
    "shap.summary_plot(shap_vals, subset)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
